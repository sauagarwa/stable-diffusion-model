{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6893973-38c2-42a9-bab7-92e200697140",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers\n",
      "  Downloading diffusers-0.30.3-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m228.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/app-root/lib/python3.9/site-packages (1.12.0)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m201.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/app-root/lib/python3.9/site-packages (from diffusers) (8.0.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.1/436.1 kB\u001b[0m \u001b[31m272.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.23.2\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m278.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/app-root/lib/python3.9/site-packages (from diffusers) (10.3.0)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib/python3.9/site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from diffusers) (3.15.4)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.9.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.0/782.0 kB\u001b[0m \u001b[31m291.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Collecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m228.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.9/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.9/site-packages (from importlib-metadata->diffusers) (3.19.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->diffusers) (2024.6.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->diffusers) (1.26.19)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->diffusers) (3.7)\n",
      "Installing collected packages: scipy, safetensors, regex, huggingface-hub, tokenizers, diffusers, transformers\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.12.0\n",
      "    Uninstalling scipy-1.12.0:\n",
      "      Successfully uninstalled scipy-1.12.0\n",
      "Successfully installed diffusers-0.30.3 huggingface-hub-0.25.1 regex-2024.9.11 safetensors-0.4.5 scipy-1.13.1 tokenizers-0.20.0 transformers-4.45.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade diffusers transformers scipy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2dcf36-5d4c-4d1b-a5f5-fd56b73fd637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f445ff9657214ff3afd06be1dc5a5591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3723247d0cb04def93fd2c9c3dd77f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fde315532f1471aaafe0b7667f25ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c7e31f59334bf1a5d61a6ae4025a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f15374b343c4b0f8a12b5d0fbe25cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90e3785e99f4e24a44522358dd4efbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "safety_checker/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19317b9a8bd477a825baa1e30399f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7806578c4766450da3ca4dde3d094397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b874f263c114565be104c95c3b10f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5732ec32ab734b01bb690d2e5f45bfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37a05a2b3c84a5abed0ab1fc231cbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa3cd6c52874ba395439a9f303fbb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)kpoints/scheduler_config-checkpoint.json:   0%|          | 0.00/209 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72b397e4e69429fbc146079193ba9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2166fe4136ca49b1b958e2c4b1bb5c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bf7a01949c46549d5ea9cc639aa5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76d2f39daad45979010a22b57af6ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf634f743564090af1d983caab44735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe0b3f4bf8047209d44563fb0e14006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0722aee7c94091931c66d5dcf9bbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d421e64f0fa44b008587a9c32f600e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]  \n",
    "    \n",
    "image.save(\"astronaut_rides_horse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f62ff795-de89-4ef3-8983-cb6286508820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7d44daa2af4054a7129ee5fcb3d84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]  \n",
    "    \n",
    "image.save(\"astronaut_rides_horse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91955607-ca53-43fa-83dd-b11613288c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-model-archiver\n",
      "  Downloading torch_model_archiver-0.12.0-py3-none-any.whl (16 kB)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Installing collected packages: enum-compat, torch-model-archiver\n",
      "Successfully installed enum-compat-0.0.3 torch-model-archiver-0.12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-model-archiver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe4150d-c53e-4563-a982-a3f17e34f4ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe.save_pretrained(\"./Diffusion_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a129b73f-2af7-4591-844d-13f710e8bba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd Diffusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82400aba-23aa-4cc9-a9e4-a0322cc3401a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astronaut_rides_horse.png  diffuser.ipynb  Diffusion_model  lost+found\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f76d12a0-ab11-4906-97ac-b425b3fffc72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd Diffusion_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0315e40-266c-4c98-8f45-1ae6ce91cda0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\"' for software license.\n",
      "Zip 3.0 (July 5th 2008). Usage:\n",
      "zip [-options] [-b path] [-t mmddyyyy] [-n suffixes] [zipfile list] [-xi list]\n",
      "  The default action is to add or replace zipfile entries from list, which\n",
      "  can include the special name - to compress standard input.\n",
      "  If zipfile and list are omitted, zip compresses stdin to stdout.\n",
      "  -f   freshen: only changed files  -u   update: only changed or new files\n",
      "  -d   delete entries in zipfile    -m   move into zipfile (delete OS files)\n",
      "  -r   recurse into directories     -j   junk (don't record) directory names\n",
      "  -0   store only                   -l   convert LF to CR LF (-ll CR LF to LF)\n",
      "  -1   compress faster              -9   compress better\n",
      "  -q   quiet operation              -v   verbose operation/print version info\n",
      "  -c   add one-line comments        -z   add zipfile comment\n",
      "  -@   read names from stdin        -o   make zipfile as old as latest entry\n",
      "  -x   exclude the following names  -i   include only the following names\n",
      "  -F   fix zipfile (-FF try harder) -D   do not add directory entries\n",
      "  -A   adjust self-extracting exe   -J   junk zipfile prefix (unzipsfx)\n",
      "  -T   test zipfile integrity       -X   eXclude eXtra file attributes\n",
      "  -y   store symbolic links as the link instead of the referenced file\n",
      "  -e   encrypt                      -n   don't compress these suffixes\n",
      "  -h2  show more help\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "!zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df4d4f6-d90b-4b62-8c9f-f61a1844ce36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - Overwriting model_artifacts/stable-diffusion.mar ...\n"
     ]
    }
   ],
   "source": [
    "!torch-model-archiver \\\n",
    "-f \\\n",
    "--model-name stable-diffusion \\\n",
    "--version 1.0 \\\n",
    " --handler model_artifacts/handler.py \\\n",
    "--export-path model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77a33ed-d3e1-44cb-9829-c2f516224dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /opt/app-root/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "work_dir=os.getcwd()\n",
    "print(f\"Current working directory: {work_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4347b5a1-5d36-40ad-94c4-e931c3a14668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!(cd {work_dir}/model && torch-model-archiver --model-name stable-diffusion --version 1.0 --handler stable_diffusion_handler.py --extra-files model.zip -r requirements.txt -f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e4bab74-0e5c-4069-8ce2-2e820a9b258b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "aws_access_key_id = \"minio\"\n",
    "aws_secret_access_key = \"minio123\"\n",
    "endpoint_url = \"https://minio-api-worldline.apps.ai-dev02.kni.syseng.devcluster.openshift.com\"\n",
    "region_name = \"us-east-1\"\n",
    "bucket_name = \"stable-diffusion-mar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50cb8022-9afa-4311-b703-d13d1d60d8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.9/site-packages (1.34.135)\n",
      "Requirement already satisfied: botocore in /opt/app-root/lib/python3.9/site-packages (1.34.135)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/app-root/lib/python3.9/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib/python3.9/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/app-root/lib/python3.9/site-packages (from botocore) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8309e13f-f115-49a1-9b8c-28c500e77d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not all([aws_access_key_id, aws_secret_access_key, endpoint_url, region_name, bucket_name]):\n",
    "    raise ValueError(\"One or data connection variables are empty.  \"\n",
    "                     \"Please check your data connection to an S3 bucket.\")\n",
    "\n",
    "session = boto3.session.Session(aws_access_key_id=aws_access_key_id,\n",
    "                                aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name)\n",
    "\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    num_files = 0\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path)\n",
    "            print(f\"{file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "            num_files += 1\n",
    "    return num_files\n",
    "\n",
    "\n",
    "def list_objects(prefix):\n",
    "    filter = bucket.objects.filter(Prefix=prefix)\n",
    "    for obj in filter.all():\n",
    "        print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0db0e96f-f10f-4bc5-b526-1bebca4f7edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_objects(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b539f00-a61f-4f3e-a286-22139498cae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/model/stable_diffusion_handler.py -> models/stable_diffusion_handler.py\n",
      "/opt/app-root/src/model/requirements.txt -> models/requirements.txt\n",
      "/opt/app-root/src/model/stable-diffusion.mar -> models/stable-diffusion.mar\n",
      "/opt/app-root/src/model/config.properties -> models/config.properties\n",
      "/opt/app-root/src/model/model.zip -> models/model.zip\n",
      "/opt/app-root/src/model/.ipynb_checkpoints/requirements-checkpoint.txt -> models/.ipynb_checkpoints/requirements-checkpoint.txt\n",
      "/opt/app-root/src/model/.ipynb_checkpoints/config-checkpoint.properties -> models/.ipynb_checkpoints/config-checkpoint.properties\n",
      "/opt/app-root/src/model/.ipynb_checkpoints/stable_diffusion_handler-checkpoint.py -> models/.ipynb_checkpoints/stable_diffusion_handler-checkpoint.py\n"
     ]
    }
   ],
   "source": [
    "model_dir = work_dir + \"/model\"\n",
    "\n",
    "if not os.path.isdir(model_dir):\n",
    "    raise ValueError(f\"The directory '{model_dir}' does not exist.  \"\n",
    "                     \"Did you finish training the model in the previous notebook?\")\n",
    "\n",
    "num_files = upload_directory_to_s3(model_dir, \"models\")\n",
    "\n",
    "if num_files == 0:\n",
    "    raise ValueError(f\"No files uploaded. Check the {model_dir} directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff2fc4c3-af66-4bbf-9ec9-18d427597d49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/.ipynb_checkpoints/config-checkpoint.properties\n",
      "models/.ipynb_checkpoints/kserve-query-checkpoint.py\n",
      "models/.ipynb_checkpoints/torchserver-query-checkpoint.py\n",
      "models/config.properties\n",
      "models/kserve-query.py\n",
      "models/model.zip\n",
      "models/requirements.txt\n",
      "models/stable-diffusion.mar\n",
      "models/stable_diffusion_handler.py\n",
      "models/torchserver-query.py\n"
     ]
    }
   ],
   "source": [
    "list_objects(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a155e1-8e12-4aa6-a2b6-ba0aac7dad1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_url=\"https://stable-diffusion-rag-llm.apps.cluster-ccczq.ccczq.sandbox1168.opentlc.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2923c153-5a5d-4db5-8684-222a273c2048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (Forbidden): inferenceservices.serving.kserve.io \"stable-diffusion\" is forbidden: User \"system:serviceaccount:worldline:pytorch\" cannot get resource \"inferenceservices\" in API group \"serving.kserve.io\" in the namespace \"distributed\"\n",
      "Waiting for inference service to be ready...\n",
      "Error from server (Forbidden): inferenceservices.serving.kserve.io \"stable-diffusion\" is forbidden: User \"system:serviceaccount:worldline:pytorch\" cannot get resource \"inferenceservices\" in API group \"serving.kserve.io\" in the namespace \"distributed\"\n",
      "Waiting for inference service to be ready...\n",
      "^C\n",
      "Inference serving is ready\n"
     ]
    }
   ],
   "source": [
    "!until oc get inferenceservice stable-diffusion -n distributed -o jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}' | grep -q True ; do \\\n",
    "   echo \"Waiting for inference service to be ready...\"; \\\n",
    "   sleep 30; \\\n",
    "done\n",
    "\n",
    "print(\"Inference serving is ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a65b520-05e8-40e8-9b3a-74d75af82510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (Forbidden): inferenceservices.serving.kserve.io \"stable-diffusion\" is forbidden: User \"system:serviceaccount:worldline:pytorch\" cannot get resource \"inferenceservices\" in API group \"serving.kserve.io\" in the namespace \"worldline\"\n"
     ]
    }
   ],
   "source": [
    "!oc get inferenceservice stable-diffusion -n worldline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b7909d-986c-45a0-b880-3dc0b4b3fd6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/urllib3/connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host 'stable-diffusion-rag-llm.apps.cluster-ccczq.ccczq.sandbox1168.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "uniq_token = 'unqtkn'\n",
    "class_name = 'dog'\n",
    "my_prompt = f'photo of {uniq_token} {class_name} in a sand castle'\n",
    "\n",
    "!python {work_dir}/model-2/kserve-query.py --url=\"{model_url}/v1/models/stable-diffusion:predict\" --prompt \"{my_prompt}\" --filename output.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c2e19d5-bf9a-4a02-b4b2-c93fbd713185",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local tuned model dir: /opt/app-root/src/Diffusion_model\n"
     ]
    }
   ],
   "source": [
    "tuned_model_dir = f\"{work_dir}/Diffusion_model\"\n",
    "print(f\"Local tuned model dir: {tuned_model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b9afe22-9de8-48e3-b8df-9b2980435813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: feature_extractor/ (stored 0%)\n",
      "  adding: feature_extractor/preprocessor_config.json (deflated 48%)\n",
      "  adding: model_index.json (deflated 56%)\n",
      "  adding: safety_checker/ (stored 0%)\n",
      "  adding: safety_checker/model.safetensors (deflated 8%)\n",
      "  adding: safety_checker/config.json (deflated 49%)\n",
      "  adding: scheduler/ (stored 0%)\n",
      "  adding: scheduler/scheduler_config.json (deflated 41%)\n",
      "  adding: text_encoder/ (stored 0%)\n",
      "  adding: text_encoder/model.safetensors (deflated 8%)\n",
      "  adding: text_encoder/config.json (deflated 43%)\n",
      "  adding: tokenizer/ (stored 0%)\n",
      "  adding: tokenizer/special_tokens_map.json (deflated 73%)\n",
      "  adding: tokenizer/vocab.json (deflated 71%)\n",
      "  adding: tokenizer/tokenizer_config.json (deflated 64%)\n",
      "  adding: tokenizer/merges.txt (deflated 60%)\n",
      "  adding: unet/ (stored 0%)\n",
      "  adding: unet/diffusion_pytorch_model.safetensors (deflated 8%)\n",
      "  adding: unet/config.json (deflated 63%)\n",
      "  adding: vae/ (stored 0%)\n",
      "  adding: vae/diffusion_pytorch_model.safetensors (deflated 8%)\n",
      "  adding: vae/config.json (deflated 55%)\n"
     ]
    }
   ],
   "source": [
    "!(cd {tuned_model_dir} && zip -r {work_dir}/model/model.zip *)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02b3d0f8-d50a-4e6a-a0f6-25279bd7ac08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!(cd {work_dir}/model && torch-model-archiver --model-name stable-diffusion --version 1.0 --handler stable_diffusion_handler.py --extra-files model.zip -r requirements.txt -f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289535e9-b827-470d-8400-4b1bec38f625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
